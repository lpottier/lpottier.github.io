@incollection{chapter2016crc,
 abstract = {Big data applications play an increasing role in high-performance computing. They are perfect candidates for co-scheduling, as they obey flexible speedup models, alternating I/O operations and intensive computation phases. In this chapter, we discuss co-scheduling on failure-prone platforms. Checkpointing helps to mitigate the impact of a failure on a given application, but it must be complemented by redistributions to rebalance the load among all applications. Co-scheduling usually involves partitioning the applications into packs, and then scheduling each pack in sequence, as efficiently as possible. The objective is therefore to determine a partition into packs, and an assignment of processors to applications, that minimize the sum of the execution times of the packs. On the theoretical side, we assess the problem complexity. On the practical side, we design several polynomial-time heuristics to deal with the general problem with failures and redistribution costs. The proposed heuristics show very good performance while executing in very short time, hence validating the approach.},
 author = {Guillaume Aupy and Anne Benoit and Lo√Øc Pottier and Padma Raghavan and Yves Robert and Manu Shantharam},
 booktitle = {Big Data Management and Processing},
 chapter = {5},
 doi = {10.1201/9781315154008-5},
 editor = {Kuan-Ching Li and Hai Jiang and Albert Zomaya},
 keywords = {mine,ensl},
 month = {05},
 pages = {81--104},
 publisher = {Chapman and Hall/CRC Press},
 title = {Co-scheduling high-performance computing applications},
 url = {https://doi.org/10.1201/9781315154008-5},
 year = {2017}
}


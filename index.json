[{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m currently a computer scientist at the Information Sciences Institute which is part of the University of Southern California in Los Angeles. I am part of the Science Automation Technologies group led by Dr Ewa Deelman where I am working on scientific workflows management on large-scale cyber-infrastructures and, I am also working on optimizing machine learning workflows to run on high-performance systems (HPC).\nI have defended my PhD in Computer Science at École Normale Supérieure (ENS Lyon), France, in 2018, under the supervision of Anne Benoit and Yves Robert. I was part of the team ROMA at the LIP. I was mainly working on co-scheduling algorithms for large-scale applications. I was also working on scheduling and data management problems on the new many-core architectures.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://loicpottier.com/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I\u0026rsquo;m currently a computer scientist at the Information Sciences Institute which is part of the University of Southern California in Los Angeles. I am part of the Science Automation Technologies group led by Dr Ewa Deelman where I am working on scientific workflows management on large-scale cyber-infrastructures and, I am also working on optimizing machine learning workflows to run on high-performance systems (HPC).\nI have defended my PhD in Computer Science at École Normale Supérieure (ENS Lyon), France, in 2018, under the supervision of Anne Benoit and Yves Robert.","tags":null,"title":"","type":"authors"},{"authors":[],"categories":[],"content":"","date":1581206674,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581206674,"objectID":"5aab0bdd432e70e52e908e2735409619","permalink":"https://loicpottier.com/project/cicoe-pilot/","publishdate":"2020-02-08T16:04:34-08:00","relpermalink":"/project/cicoe-pilot/","section":"project","summary":"Pilot Study for a Cyberinfrastructure Center of Excellence","tags":["cyberinfrastructure","NSF","pilot"],"title":"CI CoE Pilot","type":"project"},{"authors":[],"categories":[],"content":"","date":1581206670,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581206670,"objectID":"bae2f47186023b3735eb1502924f16af","permalink":"https://loicpottier.com/project/panorama360/","publishdate":"2020-02-08T16:04:30-08:00","relpermalink":"/project/panorama360/","section":"project","summary":"Performance Data Capture and Analysis for End-to-end Scientific Workflows","tags":["doe","workflows","performance monitoring"],"title":"Panorama360","type":"project"},{"authors":[],"categories":["HPC","NSF","in-situ"],"content":"","date":1581206651,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581206651,"objectID":"e38dcc5d64a5465df8122c8c32d5d141","permalink":"https://loicpottier.com/project/a4md/","publishdate":"2020-02-08T16:04:11-08:00","relpermalink":"/project/a4md/","section":"project","summary":"In Situ Data Analytics for Next Generation Molecular Dynamics Workflows","tags":[],"title":"Analytics4MD","type":"project"},{"authors":["Tu Mai Anh Do","Loïc Pottier","Silvina Caíno-Lores","Rafael Ferreira da Silva","Michel A. Cuendet","Harel Weinstein","Trilce Estrada","Michela Taufer","Ewa Deelman"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612231131,"objectID":"13736be6a2021fcf12c1983ba0647e0a","permalink":"https://loicpottier.com/publication/do-2020-jocs/","publishdate":"2021-02-02T02:21:50.316072Z","relpermalink":"/publication/do-2020-jocs/","section":"publication","summary":"","tags":[],"title":"A Lightweight Method for Evaluating In Situ Workflow Efficiency","type":"publication"},{"authors":["Tu Mai Anh Do","Loic Pottier","Stephen Thomas","Rafael Ferreira da Silva","Michel A. Cuendet","Harel Weinstein","Trilce Estrada","Michela Taufer","Ewa Deelman"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612231132,"objectID":"cc4fce2657b636fbd381a5950d65d69e","permalink":"https://loicpottier.com/publication/do-2020-iccs/","publishdate":"2021-02-02T02:21:50.726508Z","relpermalink":"/publication/do-2020-iccs/","section":"publication","summary":"","tags":[],"title":"A Novel Metric to Evaluate In Situ Workflows","type":"publication"},{"authors":["Loic Pottier","Rafael Ferreira da Silva","Henri Casanova","Ewa Deelman"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612231132,"objectID":"e0cf10751c11235261a9589f803ff084","permalink":"https://loicpottier.com/publication/pottier-2020-cluster/","publishdate":"2021-02-02T02:21:50.933221Z","relpermalink":"/publication/pottier-2020-cluster/","section":"publication","summary":"","tags":[],"title":"Modeling the Performance of Scientific Workflow Executions on HPC Platforms with Burst Buffers","type":"publication"},{"authors":["Rafael Ferreira da Silva","Loïc Pottier","Tainã Coleman","Ewa Deelman","Henri Casanova"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612231132,"objectID":"02cbb93a6d25006f70ca0d2a8b1a1989","permalink":"https://loicpottier.com/publication/ferreiradasilva-2020-works/","publishdate":"2021-02-02T02:21:50.829946Z","relpermalink":"/publication/ferreiradasilva-2020-works/","section":"publication","summary":"","tags":[],"title":"WorkflowHub: Community Framework for Enabling Scientific Workflow Research and Development","type":"publication"},{"authors":["Guillaume Aupy","Anne Benoit","Brice Goglin","Loïc Pottier","Yves Robert"],"categories":null,"content":"","date":1554076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554076800,"objectID":"7ea28c940d5c52f70a17f7eadaff06a6","permalink":"https://loicpottier.com/publication/ijhpca-2019-cmp/","publishdate":"2021-02-02T02:21:50.420164Z","relpermalink":"/publication/ijhpca-2019-cmp/","section":"publication","summary":" With the recent advent of many-core architectures such as chip multiprocessors (CMPs), the number of processing units accessing a global shared memory is constantly increasing. Co-scheduling techniques are used to improve application throughput on such architectures, but sharing resources often generates critical interferences. In this article, we focus on the interferences in the last level of cache (LLC) and use the Cache Allocation Technology (CAT) recently provided by Intel to partition the LLC and give each co-scheduled application their own cache area. We consider m iterative HPC applications running concurrently and answer to the following questions: (i) How to precisely model the behavior of these applications on the cache-partitioned platform? and (ii) how many cores and cache fractions should be assigned to each application to maximize the platform efficiency? Here, platform efficiency is defined as maximizing the performance either globally, or as guaranteeing a fixed ratio of iterations per second for each application. Through extensive experiments using CAT, we demonstrate the impact of cache partitioning when multiple HPC applications are co-scheduled onto CMP platforms. ","tags":["\"mine\"","\"ensl\""],"title":"Co-scheduling HPC workloads on cache-partitioned CMP platforms","type":"publication"},{"authors":["Stephen Thomas","Michael Wyatt","Tu Mai Anh Do","Loïc Pottier","Rafael Ferreira da Silva","Harel Weinstein","Michel A. Cuendet","Trilce Estrada","Ewa Deelman","Michela Taufer"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"d6c2689a0c20c6c6e9fc96cfafac4cc3","permalink":"https://loicpottier.com/publication/thomas-escience-2019/","publishdate":"2021-02-02T02:21:51.250463Z","relpermalink":"/publication/thomas-escience-2019/","section":"publication","summary":"","tags":["\"mine\"","\"isi\""],"title":"Characterization of In Situ and In Transit Analytics of Molecular Dynamics Simulations for Next-generation Supercomputers","type":"publication"},{"authors":["Ewa Deelman","Anirban Mandal","Valerio Pascucci","Susan Sons","Jane Wyngaard","Charles F Vardeman II","Steve Petruzza","Ilya Baldin","Laura Christopherson","Ryan Mitchell","Loïc Pottier","Mats Rynge","Erik Scott","Karan Vahi","Marina Kogank","Jasmine A Mann","Tom Gulbransen","Daniel Allen","David Barlow","Santiago Bonarrigo","Chris Clark","Leslie Goldman","Tristan Goulden","Phil Harvey","David Hulsander","Steve Jacob","Christine Laney","Ivan Lobo-Padilla","Jeremey Sampson","John Staarmann","Steve Stone"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"623c6c1850e82081844608844b25a01a","permalink":"https://loicpottier.com/publication/deelman-escience-2019/","publishdate":"2021-02-02T02:21:51.043949Z","relpermalink":"/publication/deelman-escience-2019/","section":"publication","summary":"","tags":["\"mine\"","\"isi\""],"title":"Cyberinfrastructure Center of Excellence Pilot: Connecting Large Facilities Cyberinfrastructure","type":"publication"},{"authors":["Ryan Mitchell","Loïc Pottier","Steve Jacobs","Rafael Ferreira da Silva","Mats Rynge","Karan Vahi","Ewa Deelman"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"8d4af8ffceff6d9a223cb761439d01ec","permalink":"https://loicpottier.com/publication/mitchell-2019-btsd/","publishdate":"2021-02-02T02:21:51.150326Z","relpermalink":"/publication/mitchell-2019-btsd/","section":"publication","summary":"","tags":["\"mine\"","\"isi\""],"title":"Exploration of Workflow Management Systems Emerging Features from Users Perspectives","type":"publication"},{"authors":["Loïc Pottier"],"categories":null,"content":"","date":1535760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535760000,"objectID":"ba4480d83f0059dbea17c5fb0de27ec9","permalink":"https://loicpottier.com/publication/pottier-2018/","publishdate":"2021-02-02T02:21:49.911418Z","relpermalink":"/publication/pottier-2018/","section":"publication","summary":"","tags":["\"mine\"","\"ensl\"","\"Co-scheduling algorithm\"","\"Memory hierarchy\"","\"Cache memory\"","\"Scheduling\"","\"Resilience\"","\"High performance computing\"","\"HPC\"","\"Memory\"","\"Many-core\"","\"Ordonnancement concurrent\"","\"Hiérarchie mémoire\"","\"Algorithme d'ordonnancement\"","\"Résilience\"","\"Informatique haute performance\"","\"Antémémoire\""],"title":"Co-scheduling for large-scale applications: memory and resilience","type":"publication"},{"authors":["Anne Benoit","Swann Perarnau","Loïc Pottier","Yves Robert"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"30205074c552ba06fa29102dad4b0ac6","permalink":"https://loicpottier.com/publication/icpp-2018/","publishdate":"2021-02-02T02:21:51.453573Z","relpermalink":"/publication/icpp-2018/","section":"publication","summary":"This work presents a realistic performance model to execute scientific workflows on high-bandwidth-memory architectures such as the Intel Knights Landing. We provide a detailed analysis of the execution time on such platforms, taking into account transfers from both fast and slow memory and their overlap with computations. We discuss several scheduling and mapping strategies: not only tasks must be assigned to computing resources, but also one has to decide which fraction of input and output data will reside in fast memory and which will have to stay in slow memory. We use extensive simulations to assess the impact of the mapping strategies on performance. We also conduct experiments for a simple 1D Gauss-Seidel kernel, which assess the accuracy of the model and further demonstrate the importance of a tuned memory management. Our model and results lay the foundations for further studies and experiments on dual-memory systems.","tags":["\"mine\"","\"ensl\""],"title":"A Performance Model to Execute Workflows on High-Bandwidth-Memory Architectures","type":"publication"},{"authors":["Guillaume Aupy","Anne Benoit","Sicheng Dai","Loïc Pottier","Padma Raghavan","Yves Robert","Manu Shantharam"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"d9ac44fc7ae751edfe7100e276f53d8d","permalink":"https://loicpottier.com/publication/ijhpca-2018-cache/","publishdate":"2021-02-02T02:21:50.622045Z","relpermalink":"/publication/ijhpca-2018-cache/","section":"publication","summary":" Cache-partitioned architectures allow subsections of the shared last-level cache (LLC) to be exclusively reserved for some applications. This technique dramatically limits interactions between applications that are concurrently executing on a multicore machine. Consider n applications that execute concurrently, with the objective to minimize the makespan, defined as the maximum completion time of the n applications. Key scheduling questions are as follows: (i) which proportion of cache and (ii) how many processors should be given to each application? In this article, we provide answers to (i) and (ii) for Amdahl applications. Even though the problem is shown to be NP-complete, we give key elements to determine the subset of applications that should share the LLC (while remaining ones only use their smaller private cache). Building upon these results, we design efficient heuristics for Amdahl applications. Extensive simulations demonstrate the usefulness of co-scheduling when our efficient cache partitioning strategies are deployed. ","tags":["\"mine\"","\"ensl\""],"title":"Co-scheduling Amdahl applications on cache-partitioned systems","type":"publication"},{"authors":["Guillaume Aupy","Anne Benoit","Brice Goglin","Loïc Pottier","Yves Robert"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"057561b92f8e30aed6d809ca3069c0e6","permalink":"https://loicpottier.com/publication/cluster-18/","publishdate":"2021-02-02T02:21:51.348663Z","relpermalink":"/publication/cluster-18/","section":"publication","summary":"Co-scheduling techniques are used to improve the throughput of applications on chip multiprocessors (CMP), but sharing resources often generates critical interferences. We focus on the interferences in the last level of cache (LLC) and use the Cache Allocation Technology (CAT) recently provided by Intel to partition the LLC and give each co-scheduled application their own cache area. We consider m iterative HPC applications running concurrently and answer the following questions: (i) how to precisely model the behavior of these applications on the cache partitioned platform? and (ii) how many cores and cache fractions should be assigned to each application to maximize the platform efficiency? Here, platform efficiency is defined as maximizing the performance either globally, or as guaranteeing a fixed ratio of iterations per second for each application. Through extensive experiments using CAT, we demonstrate the impact of cache partitioning when multiple HPC application are co-scheduled onto CMP platforms.","tags":["\"mine\"","\"ensl\""],"title":"Co-Scheduling HPC Workloads on Cache-Partitioned CMP Platforms","type":"publication"},{"authors":["Anne Benoit","Loïc Pottier","Yves Robert"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"38dac9b6e497ca78dc03524ec67dcac1","permalink":"https://loicpottier.com/publication/ijhpca-2018-resilience/","publishdate":"2021-02-02T02:21:50.521143Z","relpermalink":"/publication/ijhpca-2018-resilience/","section":"publication","summary":" Recently, the benefits of co-scheduling several applications have been demonstrated in a fault-free context, both in terms of performance and energy savings. However, large-scale computer systems are confronted by frequent failures, and resilience techniques must be employed for large applications to execute efficiently. Indeed, failures may create severe imbalance between applications and significantly degrade performance. In this article, we aim at minimizing the expected completion time of a set of co-scheduled applications. We propose to redistribute the resources assigned to each application upon the occurrence of failures, and upon the completion of some applications, in order to achieve this goal. First, we introduce a formal model and establish complexity results. The problem is NP-complete for malleable applications, even in a fault-free context. Therefore, we design polynomial-time heuristics that perform redistributions and account for processor failures. A fault simulator is used to perform extensive simulations that demonstrate the usefulness of redistribution and the performance of the proposed heuristics. ","tags":["\"mine\"","\"ensl\""],"title":"Resilient co-scheduling of malleable applications","type":"publication"},{"authors":["Guillaume Aupy","Anne Benoit","Loïc Pottier","Padma Raghavan","Yves Robert","Manu Shantharam"],"categories":null,"content":"","date":1493596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493596800,"objectID":"1fb47393790cbabed77331cc247b4fce","permalink":"https://loicpottier.com/publication/apdcm-2017/","publishdate":"2021-02-02T02:21:51.559369Z","relpermalink":"/publication/apdcm-2017/","section":"publication","summary":"Cache-partitioned architectures allow subsections of the shared last-level cache (LLC) to be exclusively reserved for some applications. This technique dramatically limits interactions between applications that are concurrently executing on a multicore machine. Consider n applications that execute concurrently, with the objective to minimize the makespan, defined as the maximum completion time of the n applications. Key scheduling questions are: (i) which proportion of cache and (ii) how many processors should be given to each application? Here, we assign rational numbers of processors to each application, since they can be shared across applications through multi-threading. In this paper, we provide answers to (i) and (ii) for perfectly parallel applications. Even though the problem is shown to be NP-complete, we give key elements to determine the subset of applications that should share the LLC (while remaining ones only use their smaller private cache). Building upon these results, we design efficient heuristics for general applications. Extensive simulations demonstrate the usefulness of co-scheduling when our efficient cache partitioning strategies are deployed.","tags":["\"mine\"","\"ensl\""],"title":"Co-Scheduling Algorithms for Cache-Partitioned Systems","type":"publication"},{"authors":["Guillaume Aupy","Anne Benoit","Loïc Pottier","Padma Raghavan","Yves Robert","Manu Shantharam"],"categories":null,"content":"","date":1493596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493596800,"objectID":"aa40ed347dd7c0010d71b168a88a1954","permalink":"https://loicpottier.com/publication/chapter-2016-crc/","publishdate":"2021-02-02T02:21:50.203983Z","relpermalink":"/publication/chapter-2016-crc/","section":"publication","summary":"Big data applications play an increasing role in high-performance computing. They are perfect candidates for co-scheduling, as they obey flexible speedup models, alternating I/O operations and intensive computation phases. In this chapter, we discuss co-scheduling on failure-prone platforms. Checkpointing helps to mitigate the impact of a failure on a given application, but it must be complemented by redistributions to rebalance the load among all applications. Co-scheduling usually involves partitioning the applications into packs, and then scheduling each pack in sequence, as efficiently as possible. The objective is therefore to determine a partition into packs, and an assignment of processors to applications, that minimize the sum of the execution times of the packs. On the theoretical side, we assess the problem complexity. On the practical side, we design several polynomial-time heuristics to deal with the general problem with failures and redistribution costs. The proposed heuristics show very good performance while executing in very short time, hence validating the approach.","tags":["\"mine\"","\"ensl\""],"title":"Co-scheduling high-performance computing applications","type":"publication"},{"authors":["Anne Benoit","Loïc Pottier","Yves Robert"],"categories":null,"content":"","date":1470009600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470009600,"objectID":"a6d3983a207d346800de7ccf7b240c32","permalink":"https://loicpottier.com/publication/icpp-2016/","publishdate":"2021-02-02T02:21:51.664445Z","relpermalink":"/publication/icpp-2016/","section":"publication","summary":"Recently, the benefits of co-scheduling several applications have been demonstrated in a fault-free context, both in terms of performance and energy savings. However, large-scale computer systems are confronted to frequent failures, and resilience techniques must be employed to ensure the completion of large applications. Indeed, failures may create severe imbalance between applications, and significantly degrade performance. In this paper, we propose to redistribute the resources assigned to each application upon the striking of failures, in order to minimize the expected completion time of a set of co-scheduled applications. First, we introduce a formal model and establish complexity results. When no redistribution is allowed, we can minimize the expected completion time in polynomial time, while the problem becomes NP-complete with redistributions, even in a fault-free context. Therefore, we design polynomial-time heuristics that perform redistributions and account for processor failures. A fault simulator is used to perform extensive simulations that demonstrate the usefulness of redistribution and the performance of the proposed heuristics.","tags":["\"mine\"","\"ensl\""],"title":"Resilient Application Co-scheduling with Processor Redistribution","type":"publication"}]